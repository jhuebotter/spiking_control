model:
  type: rsnn
  params:
    # num_rec_layers: ${model.num_rec_layers}
    num_layers: ${model.num_layers}
    hidden_dim: ${model.hidden_dim}
    dt: ${model.time.dt}
    repeat_input: ${model.repeat_input}
    out_style: last
    encoder: ${model.encoder}
    input:
      type: input
      kwargs: 
        input_scale: ${model.input.input_scale}
        learn_input_scale: ${model.input.learn_input_scale}
    neuron:
      type: alif
      kwargs:
        reset: sub
        tau_mem: ${model.time.tau_mem}
        tau_syn: ${model.time.tau_syn}
        tau_ada: 0.0
        learn_mem: false
        learn_syn: false
        learn_ada: false
        mem_param: single
        syn_param: single
        ada_param: single
    readout:
      type: readout
      kwargs:
        tau_mem: ${model.time.tau_mem}
        tau_syn: ${model.time.tau_syn}
    connection:
      kwargs:
        bias: true
        n_dims: ${model.connection.n_dims}
        latent_bias: ${model.connection.latent_bias}
    initializer:
      type: normal
      kwargs:
        alpha: ${model.initializer.alpha}
        mu_u: ${model.initializer.mu_u}
        time_step: ${model.time.dt}
        sigma_u: ${model.initializer.sigma_u}
        nu: ${model.initializer.nu}
        bias_scale: ${model.initializer.bias_scale}
        scaling: ${model.initializer.scaling}
    activation:
      type: ${model.activation.type}
      kwargs:
        beta: ${model.activation.beta}
    regularization:
      activity:
        - type: LowerBoundL2
          kwargs:
            strength: ${LowerBoundL2.strength}
            threshold: ${LowerBoundL2.threshold}
            basis: ${LowerBoundL2.basis}
            dims: ${LowerBoundL2.dims}
        - type: UpperBoundL2
          kwargs:
            strength: ${UpperBoundL2.strength}
            threshold: ${UpperBoundL2.threshold}
            basis: ${UpperBoundL2.basis}
            dims: ${UpperBoundL2.dims}
      weights:
      - type: L2
        kwargs:
          strength: 0.0

optimizer: ${optimizer}

learning:
  batches_per_iteration: 25
  params:
    relative_l2_weight: 1.0
    batch_size: 256
    max_norm: 30
    warmup_steps: 5