model:
  type: rsnn
  params:
    hidden_dim: 1024
    dt: ${model.time.dt}
    repeat_input: 8
    out_style: last
    input:
      type: input
      kwargs: {}
    neuron:
      type: lif
      kwargs:
        reset: sub
        tau_mem: ${model.time.tau_mem}
        tau_syn: ${model.time.tau_syn}
    readout:
      type: readout
      kwargs:
        tau_mem: ${model.time.tau_mem}
        tau_syn: ${model.time.tau_syn}
        n_readouts: 25
    connection:
      type: linear
      kwargs:
        bias: true
        # n_dims: 20
    initializer:
      type: normal
      kwargs:
        time_step: ${model.time.dt}
        sigma_u: 1.0
        nu: 100
        bias_scale: 1.0
        scaling: 1.0
    activation:
      type: ${model.activation.type}
      kwargs:
        beta: ${model.activation.beta}
    regularization:
      activity:
        - type: LowerBoundL2
          kwargs:
            strength: ${LowerBoundL2.strength}
            threshold: ${LowerBoundL2.threshold}
            basis: ${LowerBoundL2.basis}
            dims: null
        - type: UpperBoundL2
          kwargs:
            strength: ${UpperBoundL2.strength}
            threshold: ${UpperBoundL2.threshold}
            basis: ${UpperBoundL2.basis}
            dims: 1
      weights:
      - type: L2
        kwargs:
          strength: 0.001

optimizer: ${optimizer}

learning:
  batches_per_iteration: 25
  params:
    batch_size: 1024
    max_norm: 30
    warmup_steps: 5