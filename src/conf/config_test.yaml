defaults:
  - task: reacher
  - agent: pred_agent
  - policy: snn_policy
  - transition: snn_transition
  - logging: logging
  - _self_

seed: 4
experiment: test
device: cuda

model:
  time:
    dt: 0.002
    tau_mem: 0.02
    tau_syn: 0.01
  activation:
    type: sigmoidspike
    beta: 25
  connection:
    n_dims: null
  hidden_dim: 
    - 1024
    - 512
  initializer:
    sigma_u: 1.0
    nu: 75
    bias_scale: 0.0
    bias_mean: 0.0
    scaling: 1
  encoder:
    type: rbf
    kwargs:
      num_centers: 10
      sigma_scale: 1.0
      learn_sigma: false
  input:
    scaling: 1.0
    learn_scaling: true 

optimizer:
  type: adam
  params:
    lr: 0.001

LowerBoundL2:
  strength: 0.0
  threshold: -10.0
  basis: mem
UpperBoundL2:
  strength: 0.0
  threshold: 0.3
  basis: out
transition:
  wl2: 0.0
policy:
  wl2: 0.0

task:
  params:
    render_mode: rgb_array
    full_target_obs: false

run:
  load_dir: null
  prediction_unroll: 20
  eval_first: true
  early_stop_metric: "test average reward"
  early_stop_patience: 20
  early_stop_mode: "max"
  lr_decay: 0.97
  teacher_forcing_p: 1.0
  teacher_forcing_decay: 1.0
  action_noise_std: 0.0
  action_noise_decay: 1.0

plotting:
  render_every: 10
  prediction_animation_unroll: 50  # change back to 50 or so
  prediction_animation_step: 5

learning:
  total_steps: 300_000

hydra:
  run:
    dir: ./outputs/${now:%Y-%m-%d}/${now:%H-%M-%S-%f}