defaults:
  - task: reacher
  - agent: pred_agent
  - policy: prnn_policy
  - transition: prnn_transition
  - logging: logging
  - _self_

seed: 42
experiment: test_prnn
device: cuda

model:
  num_rec_layers: 1
  num_ff_layers: 1
  connection:
    n_dims: null
    latent_bias: false
  hidden_dim: 500
  initializer:
    bias_scale: 1.0
  encoder:
    #- type: identity  # this is also added when the list is empty
    - type: ${run.encoder1}
    - type: ${run.encoder2}
    #- type: linear
    #- type: rbf
    #  kwargs:
    #    num_centers: 2
    #    sigma_scale: 0.5
    #    learn_sigma: false
  input:
    scaling: 0.5
    learn_scaling: false

optimizer:
  type: adam
  params:
    lr: 0.005

transition:
  wl2: 0.0
policy:
  wl2: 0.0

run:
  encoder1: identity
  encoder2: identity
  load_dir: null
  prediction_unroll: 20
  eval_first: true
  early_stop_metric: "test average steps on target"
  early_stop_patience: 30
  early_stop_mode: "max"
  lr_decay: 0.95
  lr_warmup_steps: 0
  lr_end: 0.0005
  teacher_forcing_p: 1.0
  teacher_forcing_decay: 1.0
  teacher_forcing_warmup_steps: 10
  action_noise_std: 0.0
  action_noise_decay: 1.0
  action_reg_weight_start: 0.0
  action_reg_weight_end: 0.0
  action_reg_weight_warmup_steps: 20
  action_smoothness_reg_weight_start: 0.0
  action_smoothness_reg_weight_end: 0.0
  action_smoothness_reg_weight_warmup_steps: 20
  iterations: 150

plotting:
  render_every: 10
  prediction_animation_unroll: 50  # change back to 50 or so
  prediction_animation_step: 5

learning:
  total_steps: ${mul:${task.steps_per_iteration}, ${run.iterations}}

hydra:
  run:
    dir: ./outputs/${experiment}/${now:%Y-%m-%d}/${now:%H-%M-%S-%f}